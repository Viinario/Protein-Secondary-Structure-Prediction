{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Previsão da Estrutura Secundária de Proteínas Usando Redes Neurais\n",
    "\n",
    "Este projeto visa prever a **estrutura secundária de proteínas** a partir de suas sequências de aminoácidos utilizando **redes neurais**. A previsão da estrutura secundária de proteínas (PSSP) é uma etapa importante no entendimento da forma tridimensional das proteínas, o que está intimamente relacionado à sua função biológica. A estrutura secundária de proteínas consiste principalmente em três elementos: **hélices alfa (α-helix)**, **folhas beta (β-sheet)** e **coils** (enrolamentos).\n",
    "\n",
    "O projeto se concentra em utilizar técnicas de **deep learning** para criar um modelo capaz de classificar aminoácidos em uma dessas três classes estruturais com base na sequência fornecida. Para isso, o projeto utiliza redes neurais recorrentes, especificamente a arquitetura **LSTM (Long Short-Term Memory)**, que é conhecida por lidar bem com sequências de dados, como as sequências de aminoácidos nas proteínas.\n",
    "\n",
    "# Principais Etapas do Projeto:\n",
    "\n",
    "1. **Importação das Bibliotecas**:\n",
    "   O projeto utiliza bibliotecas como **Pandas**, **NumPy**, e ferramentas de **Machine Learning** e **Deep Learning** da **Scikit-learn** e **TensorFlow**. Essas bibliotecas são essenciais para o processamento de dados, criação do modelo, e treinamento.\n",
    "\n",
    "2. **Pré-processamento dos Dados**:\n",
    "   - **Codificação One-Hot**: As sequências de aminoácidos são convertidas em uma representação de vetor conhecida como **codificação one-hot**, onde cada aminoácido é representado por um vetor binário, facilitando a compreensão do modelo.\n",
    "   - **Padding de Sequências**: Como as proteínas têm tamanhos variados, as sequências são padronizadas para um comprimento fixo, adicionando um caractere de preenchimento (geralmente 'X') quando necessário. Isso permite que todas as entradas tenham o mesmo tamanho, o que é necessário para o treinamento da rede neural.\n",
    "\n",
    "3. **Definição da Arquitetura da Rede Neural**:\n",
    "   O modelo usa uma rede neural do tipo **LSTM**. Esta é uma variação das redes neurais recorrentes, capaz de aprender a partir de dependências de longo prazo em dados sequenciais, como ocorre em sequências de aminoácidos.\n",
    "   - **Camadas do Modelo**: A rede contém camadas LSTM e camadas densas totalmente conectadas. A camada final usa a função de ativação **softmax** para classificar os aminoácidos nas três possíveis estruturas secundárias.\n",
    "\n",
    "4. **Treinamento do Modelo**:\n",
    "   - Os dados são divididos em **conjunto de treino** e **conjunto de teste**, e o modelo é treinado para minimizar o erro na previsão das estruturas secundárias.\n",
    "   - Durante o treinamento, o modelo ajusta seus parâmetros para melhorar sua capacidade de prever corretamente a estrutura secundária de uma sequência desconhecida de aminoácidos.\n",
    "\n",
    "5. **Avaliação do Modelo**:\n",
    "   Após o treinamento, o desempenho do modelo é avaliado com base em métricas como **acurácia**, que indica a porcentagem de previsões corretas, entre outras possíveis métricas.\n",
    "\n",
    "# Objetivos do Projeto:\n",
    "\n",
    "1. **Desenvolver um modelo capaz de prever a estrutura secundária de proteínas** a partir de suas sequências de aminoácidos.\n",
    "2. Utilizar técnicas de **Machine Learning** e **Deep Learning**, em particular **redes LSTM**, que são adequadas para processar dados sequenciais.\n",
    "3. **Automatizar a análise de proteínas**: Auxiliar em pesquisas biomédicas ao oferecer uma maneira eficiente de prever a estrutura de proteínas, o que pode acelerar a compreensão de funções proteicas e o desenvolvimento de medicamentos.\n",
    "\n",
    "# Aplicações Potenciais:\n",
    "- **Descoberta de novos medicamentos**: A previsão da estrutura de proteínas pode ajudar na identificação de alvos proteicos para o desenvolvimento de novas drogas.\n",
    "- **Biologia computacional**: Ferramentas como esta são essenciais para análises estruturais em larga escala, fornecendo insights sobre como as proteínas funcionam em nível molecular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDE NEURAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definir as funções para pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os aminoácidos conhecidos\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWXY'\n",
    "\n",
    "# Função para padronizar o comprimento das sequências\n",
    "def pad_sequences(sequences, max_length, padding_char='X'):\n",
    "    return sequences.apply(lambda seq: seq.ljust(max_length, padding_char)[:max_length])\n",
    "\n",
    "# Função para codificar cada sequência de aminoácidos em uma matriz one-hot\n",
    "def one_hot_encode_sequence(seq, amino_acids):\n",
    "    amino_encoder = OneHotEncoder(categories=[list(amino_acids)], sparse_output=False)\n",
    "    seq_list = list(seq)\n",
    "    return amino_encoder.fit_transform(np.array(seq_list).reshape(-1, 1))\n",
    "\n",
    "# Aplicar o one-hot encoding a todas as sequências com padding\n",
    "def encode_sequences_fixed_length(sequences, amino_acids, max_length):\n",
    "    sequences_padded = pad_sequences(sequences, max_length)\n",
    "    seq_encoded = np.array([one_hot_encode_sequence(seq, amino_acids) for seq in sequences_padded])\n",
    "    return seq_encoded\n",
    "\n",
    "# Função para padronizar as estruturas secundárias\n",
    "def pad_sst(ssts, max_length, padding_char='C'):\n",
    "    return ssts.apply(lambda sst: sst.ljust(max_length, padding_char)[:max_length])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregar os dados e realizar o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6942, 700, 21) (6942, 700) (1736, 700, 21) (1736, 700)\n"
     ]
    }
   ],
   "source": [
    "# Carregar o conjunto de treinamento\n",
    "train_data = pd.read_csv('training_secondary_structure_train.csv')  # Substitua pelo seu caminho\n",
    "\n",
    "# Selecionar as colunas de sequência e estruturas secundárias\n",
    "seq_train = train_data['seq']\n",
    "sst3_train = train_data['sst3']\n",
    "\n",
    "# Definir o comprimento máximo das sequências\n",
    "MAX_SEQ_LENGTH = 700\n",
    "\n",
    "# Codificar as sequências de aminoácidos\n",
    "seq_encoded_train = encode_sequences_fixed_length(seq_train, amino_acids, MAX_SEQ_LENGTH)\n",
    "\n",
    "# Padronizar as estruturas secundárias\n",
    "sst3_train_padded = pad_sst(sst3_train, MAX_SEQ_LENGTH)\n",
    "\n",
    "# Codificar as estruturas secundárias\n",
    "sst_encoder = LabelEncoder()\n",
    "sst_encoded_train = np.array([sst_encoder.fit_transform(list(sst)) for sst in sst3_train_padded])\n",
    "\n",
    "# Dividir os dados em treinamento e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(seq_encoded_train, sst_encoded_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Exibir as formas dos dados\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definir e compilar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Niciu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Definir o modelo\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(700, 21), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(3, activation='softmax')))  # 3 classes (H, E, C)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.7339 - loss: 0.5514 - val_accuracy: 0.7943 - val_loss: 0.3842\n",
      "Epoch 2/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.8063 - loss: 0.3756 - val_accuracy: 0.8229 - val_loss: 0.3666\n",
      "Epoch 3/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.8261 - loss: 0.3614 - val_accuracy: 0.8285 - val_loss: 0.3576\n",
      "Epoch 4/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.8307 - loss: 0.3534 - val_accuracy: 0.8292 - val_loss: 0.3562\n",
      "Epoch 5/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.8313 - loss: 0.3523 - val_accuracy: 0.8324 - val_loss: 0.3522\n",
      "Epoch 6/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.8327 - loss: 0.3505 - val_accuracy: 0.8323 - val_loss: 0.3519\n",
      "Epoch 7/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.8305 - loss: 0.3558 - val_accuracy: 0.8309 - val_loss: 0.3523\n",
      "Epoch 8/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.8301 - loss: 0.3562 - val_accuracy: 0.8327 - val_loss: 0.3498\n",
      "Epoch 9/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.8334 - loss: 0.3495 - val_accuracy: 0.8348 - val_loss: 0.3473\n",
      "Epoch 10/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.8362 - loss: 0.3444 - val_accuracy: 0.8349 - val_loss: 0.3460\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8353 - loss: 0.3464\n",
      "Acurácia no conjunto de validação: 83.49%\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo\n",
    "score = model.evaluate(X_val, y_val)\n",
    "print(f'Acurácia no conjunto de validação: {score[1] * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
