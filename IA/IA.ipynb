{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Previsão da Estrutura Secundária de Proteínas Usando Redes Neurais\n",
    "\n",
    "Este projeto visa prever a **estrutura secundária de proteínas** a partir de suas sequências de aminoácidos utilizando **redes neurais**. A previsão da estrutura secundária de proteínas (PSSP) é uma etapa importante no entendimento da forma tridimensional das proteínas, o que está intimamente relacionado à sua função biológica. A estrutura secundária de proteínas consiste principalmente em três elementos: **hélices alfa (α-helix)**, **folhas beta (β-sheet)** e **coils** (enrolamentos).\n",
    "\n",
    "O projeto se concentra em utilizar técnicas de **deep learning** para criar um modelo capaz de classificar aminoácidos em uma dessas três classes estruturais com base na sequência fornecida. Para isso, o projeto utiliza redes neurais recorrentes, especificamente a arquitetura **LSTM (Long Short-Term Memory)**, que é conhecida por lidar bem com sequências de dados, como as sequências de aminoácidos nas proteínas.\n",
    "\n",
    "# Principais Etapas do Projeto:\n",
    "\n",
    "1. **Importação das Bibliotecas**:\n",
    "   O projeto utiliza bibliotecas como **Pandas**, **NumPy**, e ferramentas de **Machine Learning** e **Deep Learning** da **Scikit-learn** e **TensorFlow**. Essas bibliotecas são essenciais para o processamento de dados, criação do modelo, e treinamento.\n",
    "\n",
    "2. **Pré-processamento dos Dados**:\n",
    "   - **Codificação One-Hot**: As sequências de aminoácidos são convertidas em uma representação de vetor conhecida como **codificação one-hot**, onde cada aminoácido é representado por um vetor binário, facilitando a compreensão do modelo.\n",
    "   - **Padding de Sequências**: Como as proteínas têm tamanhos variados, as sequências são padronizadas para um comprimento fixo, adicionando um caractere de preenchimento (geralmente 'X') quando necessário. Isso permite que todas as entradas tenham o mesmo tamanho, o que é necessário para o treinamento da rede neural.\n",
    "\n",
    "3. **Definição da Arquitetura da Rede Neural**:\n",
    "   O modelo usa uma rede neural do tipo **LSTM**. Esta é uma variação das redes neurais recorrentes, capaz de aprender a partir de dependências de longo prazo em dados sequenciais, como ocorre em sequências de aminoácidos.\n",
    "   - **Camadas do Modelo**: A rede contém camadas LSTM e camadas densas totalmente conectadas. A camada final usa a função de ativação **softmax** para classificar os aminoácidos nas três possíveis estruturas secundárias.\n",
    "\n",
    "4. **Treinamento do Modelo**:\n",
    "   - Os dados são divididos em **conjunto de treino** e **conjunto de teste**, e o modelo é treinado para minimizar o erro na previsão das estruturas secundárias.\n",
    "   - Durante o treinamento, o modelo ajusta seus parâmetros para melhorar sua capacidade de prever corretamente a estrutura secundária de uma sequência desconhecida de aminoácidos.\n",
    "\n",
    "5. **Avaliação do Modelo**:\n",
    "   Após o treinamento, o desempenho do modelo é avaliado com base em métricas como **acurácia**, que indica a porcentagem de previsões corretas, entre outras possíveis métricas.\n",
    "\n",
    "# Objetivos do Projeto:\n",
    "\n",
    "1. **Desenvolver um modelo capaz de prever a estrutura secundária de proteínas** a partir de suas sequências de aminoácidos.\n",
    "2. Utilizar técnicas de **Machine Learning** e **Deep Learning**, em particular **redes LSTM**, que são adequadas para processar dados sequenciais.\n",
    "3. **Automatizar a análise de proteínas**: Auxiliar em pesquisas biomédicas ao oferecer uma maneira eficiente de prever a estrutura de proteínas, o que pode acelerar a compreensão de funções proteicas e o desenvolvimento de medicamentos.\n",
    "\n",
    "# Aplicações Potenciais:\n",
    "- **Descoberta de novos medicamentos**: A previsão da estrutura de proteínas pode ajudar na identificação de alvos proteicos para o desenvolvimento de novas drogas.\n",
    "- **Biologia computacional**: Ferramentas como esta são essenciais para análises estruturais em larga escala, fornecendo insights sobre como as proteínas funcionam em nível molecular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDE NEURAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar as bibliotecas necessárias\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, InputLayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. **Importar as Bibliotecas Necessárias**\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **`import pandas as pd`**: Pandas é uma biblioteca usada para manipulação e análise de dados. Ela oferece estruturas de dados flexíveis e eficientes, como DataFrames, que facilitam o trabalho com grandes volumes de dados organizados em tabelas.\n",
    "\n",
    "- **`import numpy as np`**: NumPy é uma biblioteca fundamental para computação numérica em Python. Ela fornece suporte para matrizes (arrays) e várias operações matemáticas eficientes, o que é essencial para manipular os dados que serão usados no treinamento da rede neural.\n",
    "\n",
    "- **`from sklearn.preprocessing import LabelEncoder, OneHotEncoder`**: \n",
    "  - **`LabelEncoder`**: Usado para converter rótulos categóricos em valores numéricos inteiros. Neste caso, pode ser usado para converter classes de estrutura secundária (α-helix, β-sheet, coil) em números (0, 1, 2).\n",
    "  - **`OneHotEncoder`**: Converte rótulos inteiros em representações binárias \"one-hot\", onde cada classe é representada por um vetor que tem um valor 1 em uma posição e 0 nas outras. Isso é útil quando se trabalha com dados categóricos em redes neurais.\n",
    "\n",
    "- **`from sklearn.model_selection import train_test_split`**: A função `train_test_split` é usada para dividir o conjunto de dados em dois subconjuntos: um para o treinamento do modelo e outro para validação ou teste. Isso ajuda a avaliar o desempenho do modelo em dados que ele não viu durante o treinamento.\n",
    "\n",
    "- **`import tensorflow as tf`**: TensorFlow é uma das bibliotecas mais populares para construir e treinar modelos de machine learning e deep learning. Ele fornece várias ferramentas para construir redes neurais, realizar computação numérica e treinar modelos em dados.\n",
    "\n",
    "- **`from tensorflow.keras.models import Sequential`**: O `Sequential` é um modelo simples em Keras que permite empilhar camadas de forma linear, ou seja, uma camada após a outra, facilitando a construção de redes neurais profundas.\n",
    "\n",
    "- **`from tensorflow.keras.layers import LSTM, Dense, TimeDistributed`**: \n",
    "  - **`LSTM`**: Uma camada de rede neural recorrente (RNN) chamada Long Short-Term Memory, projetada para lidar com sequências de dados, como as cadeias de aminoácidos no problema de previsão da estrutura secundária de proteínas.\n",
    "  - **`Dense`**: Uma camada totalmente conectada, onde cada neurônio recebe entrada de todos os neurônios da camada anterior. Ela é normalmente usada para a classificação final dos dados.\n",
    "  - **`TimeDistributed`**: Essa camada aplica uma operação densa (ou outra camada) a cada passo da sequência individualmente. No caso deste projeto, ela é usada para prever a classe de cada aminoácido na sequência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definir as funções para pré-processamento\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os aminoácidos conhecidos\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWXY'\n",
    "\n",
    "# Função para padronizar o comprimento das sequências\n",
    "def pad_sequences(sequences, max_length, padding_char='X'):\n",
    "    return sequences.apply(lambda seq: seq.ljust(max_length, padding_char)[:max_length])\n",
    "\n",
    "# Função para codificar cada sequência de aminoácidos em uma matriz one-hot\n",
    "def one_hot_encode_sequence(seq, amino_acids):\n",
    "    amino_encoder = OneHotEncoder(categories=[list(amino_acids)], sparse_output=False)\n",
    "    seq_list = list(seq)\n",
    "    return amino_encoder.fit_transform(np.array(seq_list).reshape(-1, 1))\n",
    "\n",
    "# Aplicar o one-hot encoding a todas as sequências com padding\n",
    "def encode_sequences_fixed_length(sequences, amino_acids, max_length):\n",
    "    sequences_padded = pad_sequences(sequences, max_length)\n",
    "    seq_encoded = np.array([one_hot_encode_sequence(seq, amino_acids) for seq in sequences_padded])\n",
    "    return seq_encoded\n",
    "\n",
    "# Função para padronizar as estruturas secundárias\n",
    "def pad_sst(ssts, max_length, padding_char='C'):\n",
    "    return ssts.apply(lambda sst: sst.ljust(max_length, padding_char)[:max_length])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. **Definir as Funções para Pré-processamento**\n",
    "\n",
    "#### a) Definir os aminoácidos conhecidos\n",
    "\n",
    "```python\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWXY'\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **`amino_acids`**: Esta variável contém os 20 aminoácidos comuns, além de um caractere adicional ('X') usado para preenchimento (padding). Ela será usada nas funções subsequentes para codificar as sequências de aminoácidos e garantir que o modelo só processe aminoácidos válidos e reconhecidos.\n",
    "\n",
    "\n",
    "#### b) Função para padronizar o comprimento das sequências\n",
    "\n",
    "```python\n",
    "def pad_sequences(sequences, max_length, padding_char='X'):\n",
    "    return sequences.apply(lambda seq: seq.ljust(max_length, padding_char)[:max_length])\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Esta função garante que todas as sequências de aminoácidos tenham o mesmo comprimento (fixo). Ela faz isso adicionando o caractere de preenchimento (`padding_char`), que por padrão é 'X', ao final das sequências mais curtas. Se uma sequência for maior que o comprimento máximo (`max_length`), ela é truncada.\n",
    "- **`sequences.apply()`**: Aplica uma operação a cada sequência individual. O método `ljust()` adiciona caracteres de preenchimento ao final da sequência até que o comprimento desejado seja atingido.\n",
    "\n",
    "\n",
    "#### c) Função para codificar cada sequência de aminoácidos em uma matriz one-hot\n",
    "\n",
    "```python\n",
    "def one_hot_encode_sequence(seq, amino_acids):\n",
    "    amino_encoder = OneHotEncoder(categories=[list(amino_acids)], sparse_output=False)\n",
    "    seq_list = list(seq)\n",
    "    return amino_encoder.fit_transform(np.array(seq_list).reshape(-1, 1))\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Esta função transforma uma sequência de aminoácidos em uma matriz de **codificação one-hot**, onde cada aminoácido é representado por um vetor binário. Por exemplo, se há 21 aminoácidos conhecidos, cada aminoácido será representado por um vetor de comprimento 21, com '1' na posição correspondente ao aminoácido e '0' em todas as outras posições.\n",
    "- **`OneHotEncoder()`**: Cria o codificador que mapeia cada aminoácido para uma representação one-hot. O parâmetro `sparse_output=False` garante que a saída seja uma matriz densa (array), em vez de uma representação esparsa.\n",
    "- **`seq_list`**: Converte a sequência em uma lista de aminoácidos, e **`fit_transform()`** aplica o codificador à lista, retornando a codificação one-hot.\n",
    "\n",
    "\n",
    "#### d) Aplicar o one-hot encoding a todas as sequências com padding\n",
    "\n",
    "```python\n",
    "def encode_sequences_fixed_length(sequences, amino_acids, max_length):\n",
    "    sequences_padded = pad_sequences(sequences, max_length)\n",
    "    seq_encoded = np.array([one_hot_encode_sequence(seq, amino_acids) for seq in sequences_padded])\n",
    "    return seq_encoded\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Esta função aplica a codificação one-hot a todas as sequências de aminoácidos, garantindo que todas as sequências tenham o mesmo comprimento (usando padding se necessário).\n",
    "- **Processo**:\n",
    "  - **`pad_sequences()`**: Primeiro, padroniza o comprimento das sequências, preenchendo as mais curtas com o caractere de preenchimento ('X').\n",
    "  - **`one_hot_encode_sequence()`**: Em seguida, cada sequência é codificada em one-hot.\n",
    "- **`np.array()`**: Converte a lista de sequências codificadas em uma matriz NumPy para facilitar a manipulação dos dados.\n",
    "\n",
    "\n",
    "#### e) Função para padronizar as estruturas secundárias\n",
    "\n",
    "```python\n",
    "def pad_sst(ssts, max_length, padding_char='C'):\n",
    "    return ssts.apply(lambda sst: sst.ljust(max_length, padding_char)[:max_length])\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Esta função garante que as sequências de **estruturas secundárias** tenham o mesmo comprimento. Assim como no caso dos aminoácidos, é utilizado um caractere de preenchimento ('C') para padronizar as sequências.\n",
    "- **`ljust()`**: Preenche as sequências mais curtas de estruturas secundárias até atingir o comprimento máximo (`max_length`), e, se necessário, corta as sequências mais longas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregar os dados e realizar o pré-processamento\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6942, 700, 21) (6942, 700) (1736, 700, 21) (1736, 700)\n"
     ]
    }
   ],
   "source": [
    "# Carregar o conjunto de treinamento\n",
    "train_data = pd.read_csv('training_secondary_structure_train.csv')  # Substitua pelo seu caminho\n",
    "\n",
    "# Selecionar as colunas de sequência e estruturas secundárias\n",
    "seq_train = train_data['seq']\n",
    "sst3_train = train_data['sst3']\n",
    "\n",
    "# Definir o comprimento máximo das sequências\n",
    "MAX_SEQ_LENGTH = 700\n",
    "\n",
    "# Codificar as sequências de aminoácidos\n",
    "seq_encoded_train = encode_sequences_fixed_length(seq_train, amino_acids, MAX_SEQ_LENGTH)\n",
    "\n",
    "# Padronizar as estruturas secundárias\n",
    "sst3_train_padded = pad_sst(sst3_train, MAX_SEQ_LENGTH)\n",
    "\n",
    "# Codificar as estruturas secundárias\n",
    "sst_encoder = LabelEncoder()\n",
    "sst_encoded_train = np.array([sst_encoder.fit_transform(list(sst)) for sst in sst3_train_padded])\n",
    "\n",
    "# Dividir os dados em treinamento e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(seq_encoded_train, sst_encoded_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Exibir as formas dos dados\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. **Carregar os Dados e Realizar o Pré-processamento**\n",
    "\n",
    "#### a) Carregar o conjunto de treinamento\n",
    "\n",
    "```python\n",
    "train_data = pd.read_csv('training_secondary_structure_train.csv')  # Substitua pelo seu caminho\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Carrega o arquivo CSV que contém o conjunto de dados de treinamento. O arquivo deve conter as sequências de aminoácidos e suas respectivas estruturas secundárias.\n",
    "- **`pd.read_csv()`**: Esta função da biblioteca `pandas` é usada para ler o arquivo CSV e armazenar os dados em um DataFrame, que facilita a manipulação e análise dos dados.\n",
    "\n",
    "\n",
    "#### b) Selecionar as colunas de sequência e estruturas secundárias\n",
    "\n",
    "```python\n",
    "seq_train = train_data['seq']\n",
    "sst3_train = train_data['sst3']\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Separa as colunas relevantes do DataFrame para pré-processamento.\n",
    "  - **`seq_train`**: Armazena as sequências de aminoácidos.\n",
    "  - **`sst3_train`**: Armazena as estruturas secundárias, que podem ser categorizadas como hélices-alfa, folhas-beta, ou coils.\n",
    "- **Uso**: As sequências e as estruturas secundárias são processadas separadamente, pois a entrada para a rede neural será a sequência de aminoácidos e a saída será a estrutura secundária prevista.\n",
    "\n",
    "\n",
    "#### c) Definir o comprimento máximo das sequências\n",
    "\n",
    "```python\n",
    "MAX_SEQ_LENGTH = 700\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Define o comprimento máximo para as sequências de aminoácidos e estruturas secundárias. \n",
    "- **Uso**: Isso garante que todas as sequências sejam padronizadas para o mesmo tamanho (700), facilitando o processamento pelos modelos de rede neural, que requerem entradas de tamanho fixo.\n",
    "\n",
    "\n",
    "#### d) Codificar as sequências de aminoácidos\n",
    "\n",
    "```python\n",
    "seq_encoded_train = encode_sequences_fixed_length(seq_train, amino_acids, MAX_SEQ_LENGTH)\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Converte as sequências de aminoácidos em uma matriz de codificação **one-hot**, garantindo que cada aminoácido seja representado como um vetor binário e que todas as sequências tenham o comprimento máximo.\n",
    "- **`encode_sequences_fixed_length()`**: Utiliza a função definida anteriormente para padronizar o comprimento das sequências e aplicar a codificação one-hot.\n",
    "- **Uso**: O modelo de rede neural só pode processar dados numéricos, então é necessário converter os aminoácidos em um formato que a rede entenda.\n",
    "\n",
    "\n",
    "#### e) Padronizar as estruturas secundárias\n",
    "\n",
    "```python\n",
    "sst3_train_padded = pad_sst(sst3_train, MAX_SEQ_LENGTH)\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Padroniza o comprimento das estruturas secundárias para que todas tenham o mesmo tamanho de 700 caracteres, adicionando 'C' (coil) como caractere de preenchimento quando necessário.\n",
    "- **`pad_sst()`**: Utiliza a função definida anteriormente para padronizar o comprimento das estruturas secundárias.\n",
    "- **Uso**: Isso garante que as estruturas secundárias tenham o mesmo formato e tamanho, o que é necessário para que sejam usadas como rótulos consistentes durante o treinamento da rede neural.\n",
    "\n",
    "#### f) Codificar as estruturas secundárias\n",
    "\n",
    "```python\n",
    "sst_encoder = LabelEncoder()\n",
    "sst_encoded_train = np.array([sst_encoder.fit_transform(list(sst)) for sst in sst3_train_padded])\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Converte as estruturas secundárias (que são originalmente letras como 'H', 'E', 'C') em números inteiros para que a rede neural possa processá-las.\n",
    "- **`LabelEncoder()`**: Codifica as classes (H para hélice-alfa, E para folha-beta, C para coil) em inteiros (por exemplo, 0, 1, 2).\n",
    "- **`fit_transform()`**: Aplica a transformação às estruturas secundárias.\n",
    "- **Uso**: As saídas da rede neural precisam estar em formato numérico, então esta etapa converte os rótulos categóricos em números.\n",
    "\n",
    "#### g) Dividir os dados em treinamento e validação\n",
    "\n",
    "```python\n",
    "X_train, X_val, y_train, y_val = train_test_split(seq_encoded_train, sst_encoded_train, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Divide os dados em dois conjuntos: um para o treinamento do modelo e outro para a validação, para avaliar o desempenho do modelo em dados que ele não viu durante o treinamento.\n",
    "- **`train_test_split()`**: A função da biblioteca `sklearn` divide os dados em treinamento e validação.\n",
    "  - **`test_size=0.2`**: Define que 20% dos dados serão usados para validação e 80% para treinamento.\n",
    "  - **`random_state=42`**: Garante que a divisão dos dados seja reproduzível, ou seja, o mesmo subconjunto será criado em cada execução.\n",
    "\n",
    "\n",
    "#### h) Exibir as formas dos dados\n",
    "\n",
    "```python\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Exibe as dimensões dos conjuntos de dados de treinamento e validação para verificar se os dados foram divididos corretamente.\n",
    "- **`X_train.shape`**: Exibe o formato dos dados de entrada (sequências de aminoácidos) para o treinamento.\n",
    "- **`y_train.shape`**: Exibe o formato dos rótulos (estruturas secundárias) para o treinamento.\n",
    "- **`X_val.shape`** e **`y_val.shape`**: Exibem o formato dos dados de validação.\n",
    "- **Uso**: Verificar as formas dos dados é útil para garantir que o processo de pré-processamento e divisão dos dados foi executado corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definir e compilar o modelo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Adicionar a camada de entrada com o argumento `shape` no lugar de `input_shape`\n",
    "model.add(InputLayer(shape=(700, 21)))  # Entrada com shape (700, 21)\n",
    "\n",
    "# Adicionar a camada LSTM\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "# Adicionar a camada de saída\n",
    "model.add(TimeDistributed(Dense(3, activation='softmax')))  # 3 classes (H, E, C)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. **Definir e Compilar o Modelo**\n",
    "\n",
    "#### a) Definir o modelo\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Cria um modelo sequencial. O `Sequential` é uma forma simples de construir uma rede neural, empilhando camadas uma após a outra de maneira linear.\n",
    "- **Uso**: Cada camada será adicionada ao modelo nesta ordem. Esse tipo de modelo é adequado quando as camadas têm uma conexão direta, como neste caso com a rede LSTM.\n",
    "\n",
    "\n",
    "#### b) Adicionar a camada de entrada\n",
    "\n",
    "```python\n",
    "model.add(InputLayer(shape=(700, 21)))  # Entrada com shape (700, 21)\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Define a camada de entrada do modelo, especificando o formato dos dados que entrarão na rede neural.\n",
    "  - **`shape=(700, 21)`**: Define que a entrada será uma sequência de 700 aminoácidos, cada um representado por um vetor de 21 características (codificação one-hot de aminoácidos).\n",
    "- **Uso**: A camada de entrada é necessária para que a rede neural saiba qual o formato dos dados de entrada que receberá.\n",
    "\n",
    "\n",
    "\n",
    "#### c) Adicionar a camada LSTM\n",
    "\n",
    "```python\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Adiciona uma camada **LSTM** (Long Short-Term Memory), que é uma rede neural recorrente (RNN) especializada em processar sequências de dados, como as sequências de aminoácidos.\n",
    "  - **`128`**: Define o número de neurônios na camada LSTM. Um número maior de neurônios aumenta a capacidade do modelo de aprender padrões complexos.\n",
    "  - **`return_sequences=True`**: Garante que a camada LSTM retorne uma saída para cada passo da sequência, em vez de apenas a última saída. Isso é necessário para prever a estrutura secundária para cada aminoácido da sequência.\n",
    "- **Uso**: LSTMs são ideais para lidar com dados sequenciais, pois conseguem manter informações ao longo do tempo, o que é essencial para entender a sequência de aminoácidos.\n",
    "\n",
    "\n",
    "\n",
    "#### d) Adicionar a camada de saída\n",
    "\n",
    "```python\n",
    "model.add(TimeDistributed(Dense(3, activation='softmax')))\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Adiciona a camada de saída, que classifica cada aminoácido em uma das três estruturas secundárias: hélice-alfa (H), folha-beta (E), ou coil (C).\n",
    "  - **`TimeDistributed()`**: Aplica a camada `Dense` a cada passo de tempo individualmente na sequência. Isso significa que o modelo produzirá uma previsão para cada aminoácido na sequência de 700 posições.\n",
    "  - **`Dense(3)`**: Define que há 3 neurônios na camada de saída, correspondendo às 3 classes de estrutura secundária.\n",
    "  - **`activation='softmax'`**: A função de ativação `softmax` é usada para classificação multiclasse. Ela retorna a probabilidade de cada classe (H, E, C) para cada aminoácido.\n",
    "- **Uso**: Esta camada prevê a estrutura secundária de cada aminoácido da sequência, fornecendo uma classificação com base nas informações aprendidas pelo modelo.\n",
    "\n",
    "\n",
    "#### e) Compilar o modelo\n",
    "\n",
    "```python\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Compilar o modelo, definindo a função de perda, o otimizador e as métricas que serão usadas para treinar e avaliar o modelo.\n",
    "  - **`loss='sparse_categorical_crossentropy'`**: A função de perda escolhida é a entropia cruzada categórica esparsa, que é apropriada quando os rótulos são inteiros (0, 1, 2 representando as classes H, E, C). Ela mede a diferença entre as previsões do modelo e os rótulos reais.\n",
    "  - **`optimizer='adam'`**: Adam é um otimizador eficiente amplamente utilizado que ajusta os pesos do modelo de forma adaptativa durante o treinamento.\n",
    "  - **`metrics=['accuracy']`**: Define a acurácia como a métrica de desempenho. A acurácia indica a porcentagem de previsões corretas que o modelo fez em relação aos rótulos reais.\n",
    "- **Uso**: A compilação do modelo é uma etapa necessária antes de iniciar o treinamento. Ela configura como o modelo vai aprender (otimizador e função de perda) e como será avaliado (métrica de acurácia).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7589 - loss: 0.5445 - val_accuracy: 0.7945 - val_loss: 0.3849\n",
      "Epoch 2/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.8023 - loss: 0.3828 - val_accuracy: 0.8183 - val_loss: 0.3705\n",
      "Epoch 3/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.8238 - loss: 0.3648 - val_accuracy: 0.8264 - val_loss: 0.3591\n",
      "Epoch 4/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.8295 - loss: 0.3554 - val_accuracy: 0.8297 - val_loss: 0.3554\n",
      "Epoch 5/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.8291 - loss: 0.3571 - val_accuracy: 0.8321 - val_loss: 0.3524\n",
      "Epoch 6/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.8326 - loss: 0.3511 - val_accuracy: 0.8327 - val_loss: 0.3508\n",
      "Epoch 7/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.8345 - loss: 0.3473 - val_accuracy: 0.8325 - val_loss: 0.3509\n",
      "Epoch 8/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.8348 - loss: 0.3467 - val_accuracy: 0.8337 - val_loss: 0.3486\n",
      "Epoch 9/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.8341 - loss: 0.3475 - val_accuracy: 0.8340 - val_loss: 0.3484\n",
      "Epoch 10/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.8348 - loss: 0.3463 - val_accuracy: 0.8331 - val_loss: 0.3493\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. **Treinar o Modelo**\n",
    "\n",
    "```python\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "- **Objetivo**: Inicia o processo de treinamento do modelo de rede neural, ajustando seus pesos para que ele aprenda a prever a estrutura secundária de proteínas com base nas sequências de aminoácidos fornecidas.\n",
    "- **`model.fit()`**: Esta função realiza o treinamento do modelo. Ela ajusta os pesos do modelo com base nos dados de entrada (`X_train`) e nas saídas esperadas (`y_train`), usando a função de perda e o otimizador definidos na compilação.\n",
    "  \n",
    "#### Parâmetros:\n",
    "- **`X_train`**: Conjunto de dados de entrada para treinamento. Contém as sequências de aminoácidos, já padronizadas e codificadas como matrizes one-hot.\n",
    "- **`y_train`**: Rótulos de treinamento, que são as estruturas secundárias (codificadas como inteiros) associadas às sequências de aminoácidos em `X_train`.\n",
    "- **`validation_data=(X_val, y_val)`**: Um conjunto de dados de validação separado que o modelo usará para avaliar seu desempenho ao final de cada época. Isso ajuda a verificar se o modelo está se ajustando bem aos dados de treinamento ou se está ocorrendo **overfitting** (quando o modelo se ajusta muito bem aos dados de treinamento, mas não generaliza bem para dados novos).\n",
    "  - **`X_val`**: Conjunto de validação de sequências de aminoácidos.\n",
    "  - **`y_val`**: Rótulos de validação (estruturas secundárias) correspondentes a `X_val`.\n",
    "- **`epochs=10`**: Define o número de épocas (iterações completas sobre o conjunto de dados de treinamento). Cada época envolve o modelo passando por todos os dados de treinamento uma vez e ajustando seus pesos.\n",
    "- **`batch_size=64`**: Define o número de amostras processadas antes de o modelo atualizar seus pesos. O modelo treina em \"lotes\" de 64 amostras por vez, o que torna o treinamento mais eficiente do que atualizar os pesos após cada amostra individualmente.\n",
    "\n",
    "#### Retorno:\n",
    "- **`history`**: O histórico do treinamento. Ele armazena os valores da perda e da acurácia tanto no treinamento quanto na validação ao longo das épocas. Esse histórico pode ser usado para visualizar o desempenho do modelo ao longo do tempo, como criando gráficos de perda e acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8337 - loss: 0.3495\n",
      "Acurácia no conjunto de validação: 83.31%\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo\n",
    "score = model.evaluate(X_val, y_val)\n",
    "print(f'Acurácia no conjunto de validação: {score[1] * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. **Avaliar o Modelo**\n",
    "\n",
    "```python\n",
    "score = model.evaluate(X_val, y_val)\n",
    "print(f'Acurácia no conjunto de validação: {score[1] * 100:.2f}%')\n",
    "```\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Objetivo**: Avalia o desempenho do modelo nos dados de validação após o treinamento. Esta etapa verifica como o modelo se comporta com dados que ele não viu durante o treinamento, ajudando a medir sua capacidade de generalização.\n",
    "\n",
    "#### Parâmetros:\n",
    "\n",
    "- **`model.evaluate()`**: Essa função mede a perda e a métrica de desempenho (neste caso, acurácia) nos dados de validação. Ela calcula esses valores ao passar as sequências de validação (`X_val`) pelo modelo e compará-las com as estruturas secundárias reais (`y_val`).\n",
    "  - **`X_val`**: Conjunto de dados de validação (sequências de aminoácidos), que o modelo usará para fazer previsões.\n",
    "  - **`y_val`**: Rótulos reais do conjunto de validação (estruturas secundárias) usados para comparar com as previsões do modelo.\n",
    "\n",
    "#### Retorno:\n",
    "\n",
    "- **`score`**: Retorna dois valores:\n",
    "  - **`score[0]`**: A perda (loss) calculada no conjunto de validação, que indica o quão distante as previsões do modelo estão das respostas reais.\n",
    "  - **`score[1]`**: A acurácia (accuracy) no conjunto de validação, que indica a porcentagem de previsões corretas feitas pelo modelo.\n",
    "\n",
    "#### Exibir a Acurácia:\n",
    "\n",
    "```python\n",
    "print(f'Acurácia no conjunto de validação: {score[1] * 100:.2f}%')\n",
    "```\n",
    "\n",
    "- **Objetivo**: Exibe a acurácia do modelo no conjunto de validação como uma porcentagem.\n",
    "  - **`score[1] * 100`**: Multiplica a acurácia (valor entre 0 e 1) por 100 para convertê-la em porcentagem.\n",
    "  - **`:.2f`**: Formata o valor da acurácia para exibir duas casas decimais.\n",
    "\n",
    "#### Uso:\n",
    "A acurácia no conjunto de validação é um indicador importante de quão bem o modelo está generalizando para novos dados. Uma acurácia alta sugere que o modelo está fazendo boas previsões e pode ser considerado eficiente para a tarefa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
